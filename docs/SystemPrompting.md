# System Prompting

System prompting are the "system message" passed to LLMs, on top of user queries. System prompting can

1. Provide LLM more information about the conversation like "who said each sentence" (user vs LLM)
2. Define specialized role and purpose of the AI application (e.g. "you are a code debugger" or "you are a oncall assistant" etc.)
3. Provide tools to LLM (e.g. MCP function definitions, see [this huggingface course](https://huggingface.co/learn/agents-course/en/unit1/tools) for more about providing tools via system prompt)
4. More ...

## Best Practice

WIP https://dev.to/simplr_sh/mastering-system-prompts-for-llms-2d1d 